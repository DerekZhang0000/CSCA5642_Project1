{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Problem Description\n",
    "\"\"\"\n",
    "# Develop an algorithm to detect cancer in pathology scans.\n",
    "# This project consists of a CNN computer vision model that will identify cancerous tissue from provided lymph node images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Exploratory Data Analysis\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "plt.bar(label_counts.index, label_counts.values, color=[\"green\", \"red\"])\n",
    "plt.xticks([0, 1], [\"No Cancer (0)\", \"Cancer Detected (1)\"])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Labels in train_labels.csv\")\n",
    "plt.show()\n",
    "\n",
    "# Based off of the EDA, we can see that there is roughly 30% more non-cancerous images in the training set than cancerous ones.\n",
    "# To account for this, we will do undersampling and reduce the non-cancerous images in training until the class counts are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model Architecture Explanation\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Since each image is 96 by 96 pixels, we will have an input layer of 96 * 96 * 3 to account for each pixel and the 3 color channels\n",
    "# There are 3 hidden layers with 512 nodes each, which was chosen arbitrarily\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 512, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(512 * 12 * 12, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 512 * 12 * 12)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = CNNModel()\n",
    "\n",
    "class CancerDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.non_cancer_count = 0\n",
    "        self.non_cancer_limit = 89117\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id, label = self.df.iloc[idx]\n",
    "        if label == 0 and self.non_cancer_count >= self.non_cancer_limit:\n",
    "            return None\n",
    "        if label == 0:\n",
    "            self.non_cancer_count += 1\n",
    "        img_path = os.path.join(\"train\", img_id + \".tif\")\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = img / 255.0\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = CancerDataset(df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "epochs = 1\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"begin training\")\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        try:\n",
    "            if data is None:\n",
    "                continue\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss / 100:.4f}\")\n",
    "                running_loss = 0.0\n",
    "        \n",
    "                train_losses.append(loss.item())\n",
    "                if i > 1000:\n",
    "                    break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Batch (x100)')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.image_ids = [f[:-4] for f in os.listdir(test_dir) if f.endswith('.tif')]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_id + \".tif\")\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = img / 255.0\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        return img_id, img\n",
    "\n",
    "test_dataset = TestDataset(\"test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, pin_memory=True)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "total_batches = len(test_loader)\n",
    "batch_size = test_loader.batch_size\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (img_ids, inputs) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        for img_id, label in zip(img_ids, predicted.cpu().numpy()):\n",
    "            predictions.append((img_id, label))\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            processed_images = (batch_idx + 1) * batch_size\n",
    "            print(f\"processed {processed_images}/{len(test_dataset)} images\")\n",
    "\n",
    "output_df = pd.DataFrame(predictions, columns=[\"id\", \"label\"])\n",
    "output_df.to_csv(\"test_predictions.csv\", index=False)\n",
    "print(\"test predictions saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Results and Analysis\"\n",
    "\"\"\"\n",
    "# The training loss stopped improving around 0.5, and the resulting model achieved an accuracy around 79%.\n",
    "# Training was not done on the entire dataset or for multiple epochs because that would have taken an unreasonable amount of time.\n",
    "# With the given training restraints, I think the model had an acceptable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Conclusion\n",
    "\"\"\"\n",
    "# The model ended up with around 79% accuracy, which is acceptable considering the limited training time and dataset constraints.\n",
    "# Since I only trained for one epoch and didnâ€™t use the full dataset, there is definitely room for improvement.\n",
    "# With more training time, data augmentation, or even a more complex model architecture, the accuracy could be pushed higher.\n",
    "# Overall, the results show that deep learning can be useful for this cancer detection task, even with a fairly simple setup."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
